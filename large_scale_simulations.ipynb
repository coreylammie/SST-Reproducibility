{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EKRhsS2eEGFE"
   },
   "source": [
    "## Required imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "p00wfQBwWDQu"
   },
   "outputs": [],
   "source": [
    "SAVE_GOOGLE_COLAB = False # Flag used to save results to a Google Drive when operating on Google Colab\n",
    "import shutil\n",
    "if SAVE_GOOGLE_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "tC-_3l07EGFF"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "L1BqTjOGEGFI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing c:\\users\\jc299170\\desktop\\sst-reproducibility\\memtorch-1.1.0.tar.gz\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from memtorch==1.1.0) (1.19.2)\n",
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (from memtorch==1.1.0) (1.1.3)\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from memtorch==1.1.0) (1.5.2)\n",
      "Requirement already satisfied: sklearn in c:\\programdata\\anaconda3\\lib\\site-packages\\sklearn-0.0-py3.8.egg (from memtorch==1.1.0) (0.0)\n",
      "Requirement already satisfied: torch>=1.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from memtorch==1.1.0) (1.7.1)\n",
      "Requirement already satisfied: torchvision in c:\\programdata\\anaconda3\\lib\\site-packages (from memtorch==1.1.0) (0.8.2)\n",
      "Requirement already satisfied: matplotlib in c:\\programdata\\anaconda3\\lib\\site-packages (from memtorch==1.1.0) (3.3.2)\n",
      "Requirement already satisfied: seaborn in c:\\programdata\\anaconda3\\lib\\site-packages (from memtorch==1.1.0) (0.11.0)\n",
      "Requirement already satisfied: ipython in c:\\programdata\\anaconda3\\lib\\site-packages (from memtorch==1.1.0) (7.19.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->memtorch==1.1.0) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->memtorch==1.1.0) (2.8.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\lib\\site-packages (from sklearn->memtorch==1.1.0) (0.23.2)\n",
      "Requirement already satisfied: typing_extensions in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.2.0->memtorch==1.1.0) (3.7.4.3)\n",
      "Requirement already satisfied: pillow>=4.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision->memtorch==1.1.0) (8.0.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->memtorch==1.1.0) (1.3.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->memtorch==1.1.0) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->memtorch==1.1.0) (0.10.0)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->memtorch==1.1.0) (2020.6.20)\n",
      "Requirement already satisfied: decorator in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython->memtorch==1.1.0) (4.4.2)\n",
      "Requirement already satisfied: traitlets>=4.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython->memtorch==1.1.0) (5.0.5)\n",
      "Requirement already satisfied: pickleshare in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython->memtorch==1.1.0) (0.7.5)\n",
      "Requirement already satisfied: pygments in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython->memtorch==1.1.0) (2.7.2)\n",
      "Requirement already satisfied: colorama; sys_platform == \"win32\" in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython->memtorch==1.1.0) (0.4.4)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython->memtorch==1.1.0) (3.0.8)\n",
      "Requirement already satisfied: backcall in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython->memtorch==1.1.0) (0.2.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython->memtorch==1.1.0) (50.3.1.post20201107)\n",
      "Requirement already satisfied: jedi>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython->memtorch==1.1.0) (0.17.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas->memtorch==1.1.0) (1.15.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn->memtorch==1.1.0) (0.17.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn->memtorch==1.1.0) (2.1.0)\n",
      "Requirement already satisfied: ipython-genutils in c:\\programdata\\anaconda3\\lib\\site-packages (from traitlets>=4.2->ipython->memtorch==1.1.0) (0.2.0)\n",
      "Requirement already satisfied: wcwidth in c:\\programdata\\anaconda3\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->memtorch==1.1.0) (0.2.5)\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jedi>=0.10->ipython->memtorch==1.1.0) (0.7.0)\n",
      "Building wheels for collected packages: memtorch\n",
      "  Building wheel for memtorch (setup.py): started\n",
      "  Building wheel for memtorch (setup.py): finished with status 'done'\n",
      "  Created wheel for memtorch: filename=memtorch-1.1.0-cp38-cp38-win_amd64.whl size=226549 sha256=cbd828611eb4bf1133c852874ceda53842c5ccf2243699214e513e8ad8c2526f\n",
      "  Stored in directory: c:\\users\\jc299170\\appdata\\local\\pip\\cache\\wheels\\fc\\26\\61\\6f750449683b8ec62006919e3ec6d44ac7d29df7275367763f\n",
      "Successfully built memtorch\n",
      "Installing collected packages: memtorch\n",
      "  Attempting uninstall: memtorch\n",
      "    Found existing installation: memtorch 1.1.0\n",
      "    Uninstalling memtorch-1.1.0:\n",
      "      Successfully uninstalled memtorch-1.1.0\n",
      "Successfully installed memtorch-1.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install memtorch-1.1.0.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Lz8ZHwREGFL"
   },
   "source": [
    "## Define and train the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "1aSs8xMiEGFL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import memtorch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n",
    "import torchvision\n",
    "from mobilenetv2 import MobileNetV2\n",
    "\n",
    "\n",
    "def set_all_seeds(seed):\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "  torch.manual_seed(seed)\n",
    "  torch.cuda.manual_seed(seed)\n",
    "  torch.backends.cudnn.deterministic = True\n",
    "\n",
    "def test(model, test_loader):\n",
    "    correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):        \n",
    "        output = model(data.to(device))\n",
    "        pred = output.data.max(1)[1]\n",
    "        correct += pred.eq(target.to(device).data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    return 100. * float(correct) / float(len(test_loader.dataset))\n",
    "\n",
    "set_all_seeds(0)\n",
    "device = torch.device('cpu' if 'cpu' in memtorch.__version__ else 'cuda')\n",
    "epochs = 100\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "train_set = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=256, shuffle=True, num_workers=1)\n",
    "test_set = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=128, shuffle=False, num_workers=1)\n",
    "model = MobileNetV2().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.1\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=40, gamma=0.1)\n",
    "best_accuracy = 0\n",
    "# for epoch in range(0, epochs):\n",
    "#     print('Epoch: [%d]\\t\\t' % (epoch + 1), end='')\n",
    "#     model.train()\n",
    "#     for batch_idx, (data, target) in enumerate(train_loader):\n",
    "#         optimizer.zero_grad()\n",
    "#         output = model(data.to(device))\n",
    "#         loss = criterion(output, target.to(device))\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#     scheduler.step()\n",
    "#     model.eval()\n",
    "#     accuracy = test(model, test_loader)\n",
    "#     print('%2.2f%%' % accuracy)\n",
    "#     if accuracy > best_accuracy:\n",
    "#         print('Saving model...')\n",
    "#         torch.save(model.state_dict(), 'trained_model.pt')\n",
    "#         best_accuracy = accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n1KCZPp9EGFN"
   },
   "source": [
    "## Validate the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "UxYRHvMiEGFO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Test Set Accuracy: \t91.65%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import memtorch\n",
    "from memtorch.utils import LoadCIFAR10\n",
    "import numpy as np\n",
    "from mobilenetv2 import MobileNetV2\n",
    "import torchvision\n",
    "\n",
    "\n",
    "def test(model, test_loader):\n",
    "    correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        output = model(data.to(device))\n",
    "        pred = output.data.max(1)[1]\n",
    "        correct += pred.eq(target.to(device).data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    return 100. * float(correct) / float(len(test_loader.dataset))\n",
    "\n",
    "device = torch.device('cuda')\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "test_set = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=128, shuffle=False, num_workers=1)\n",
    "model = MobileNetV2().to(device)\n",
    "try:\n",
    "    model.load_state_dict(torch.load('trained_model.pt'), strict=False)\n",
    "    model.eval()\n",
    "except:\n",
    "    raise Exception('trained_model.pt has not been found.')\n",
    "\n",
    "print('Test Set Accuracy: \\t%2.2f%%' % test(model, test_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patched Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) -> bh.Conv2d(in_channels=3, out_channels=32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Patched Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False) -> bh.Conv2d(in_channels=32, out_channels=32, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0))\n",
      "Patched Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False) -> bh.Conv2d(in_channels=32, out_channels=32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Patched Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False) -> bh.Conv2d(in_channels=32, out_channels=16, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0))\n",
      "Patched Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False) -> bh.Conv2d(in_channels=32, out_channels=16, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0))\n",
      "Patched Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False) -> bh.Conv2d(in_channels=16, out_channels=96, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0))\n",
      "Patched Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False) -> bh.Conv2d(in_channels=96, out_channels=96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Patched Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False) -> bh.Conv2d(in_channels=96, out_channels=24, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0))\n",
      "Patched Conv2d(16, 24, kernel_size=(1, 1), stride=(1, 1), bias=False) -> bh.Conv2d(in_channels=16, out_channels=24, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0))\n",
      "Patched Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False) -> bh.Conv2d(in_channels=24, out_channels=144, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0))\n",
      "Patched Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False) -> bh.Conv2d(in_channels=144, out_channels=144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Patched Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False) -> bh.Conv2d(in_channels=144, out_channels=24, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0))\n",
      "Patched Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False) -> bh.Conv2d(in_channels=24, out_channels=144, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0))\n",
      "Patched Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False) -> bh.Conv2d(in_channels=144, out_channels=144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "Patched Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False) -> bh.Conv2d(in_channels=144, out_channels=32, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0))\n",
      "Patched Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False) -> bh.Conv2d(in_channels=32, out_channels=192, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0))\n",
      "Patched Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False) -> bh.Conv2d(in_channels=192, out_channels=192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Patched Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False) -> bh.Conv2d(in_channels=192, out_channels=32, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0))\n",
      "Patched Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False) -> bh.Conv2d(in_channels=32, out_channels=192, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0))\n",
      "Patched Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False) -> bh.Conv2d(in_channels=192, out_channels=192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Patched Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False) -> bh.Conv2d(in_channels=192, out_channels=32, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0))\n",
      "Patched Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False) -> bh.Conv2d(in_channels=32, out_channels=192, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0))\n",
      "Patched Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False) -> bh.Conv2d(in_channels=192, out_channels=192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "Patched Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False) -> bh.Conv2d(in_channels=192, out_channels=64, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0))\n",
      "Patched Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False) -> bh.Conv2d(in_channels=64, out_channels=384, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0))\n",
      "Patched Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False) -> bh.Conv2d(in_channels=384, out_channels=384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Patched Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False) -> bh.Conv2d(in_channels=384, out_channels=64, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0))\n",
      "Patched Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False) -> bh.Conv2d(in_channels=64, out_channels=384, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0))\n",
      "Patched Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False) -> bh.Conv2d(in_channels=384, out_channels=384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Patched Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False) -> bh.Conv2d(in_channels=384, out_channels=64, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0))\n",
      "Patched Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False) -> bh.Conv2d(in_channels=64, out_channels=384, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0))\n",
      "Patched Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False) -> bh.Conv2d(in_channels=384, out_channels=384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Patched Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False) -> bh.Conv2d(in_channels=384, out_channels=64, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0))\n",
      "Patched Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False) -> bh.Conv2d(in_channels=64, out_channels=384, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0))\n",
      "Patched Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False) -> bh.Conv2d(in_channels=384, out_channels=384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Patched Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False) -> bh.Conv2d(in_channels=384, out_channels=96, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0))\n",
      "Patched Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1), bias=False) -> bh.Conv2d(in_channels=64, out_channels=96, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0))\n",
      "Patched Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False) -> bh.Conv2d(in_channels=96, out_channels=576, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0))\n",
      "Patched Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False) -> bh.Conv2d(in_channels=576, out_channels=576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Patched Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False) -> bh.Conv2d(in_channels=576, out_channels=96, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0))\n",
      "Patched Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False) -> bh.Conv2d(in_channels=96, out_channels=576, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0))\n",
      "Patched Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False) -> bh.Conv2d(in_channels=576, out_channels=576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Patched Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False) -> bh.Conv2d(in_channels=576, out_channels=96, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0))\n",
      "Patched Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False) -> bh.Conv2d(in_channels=96, out_channels=576, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0))\n",
      "Patched Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False) -> bh.Conv2d(in_channels=576, out_channels=576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "Patched Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False) -> bh.Conv2d(in_channels=576, out_channels=160, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0))\n",
      "Patched Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False) -> bh.Conv2d(in_channels=160, out_channels=960, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patched Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False) -> bh.Conv2d(in_channels=960, out_channels=960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Patched Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False) -> bh.Conv2d(in_channels=960, out_channels=160, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0))\n",
      "Patched Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False) -> bh.Conv2d(in_channels=160, out_channels=960, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0))\n",
      "Patched Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False) -> bh.Conv2d(in_channels=960, out_channels=960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Patched Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False) -> bh.Conv2d(in_channels=960, out_channels=160, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0))\n",
      "Patched Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False) -> bh.Conv2d(in_channels=160, out_channels=960, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0))\n",
      "Patched Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False) -> bh.Conv2d(in_channels=960, out_channels=960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Patched Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False) -> bh.Conv2d(in_channels=960, out_channels=320, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0))\n",
      "Patched Conv2d(160, 320, kernel_size=(1, 1), stride=(1, 1), bias=False) -> bh.Conv2d(in_channels=160, out_channels=320, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0))\n",
      "Patched Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False) -> bh.Conv2d(in_channels=320, out_channels=1280, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0))\n",
      "Patched Linear(in_features=1280, out_features=10, bias=True) -> bh.Linear(in_features=1280, out_features=10, bias=True)\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "from memtorch.mn.Module import patch_model\n",
    "from memtorch.map.Parameter import naive_map\n",
    "from memtorch.bh.crossbar.Program import naive_program\n",
    "\n",
    "r_on = 2.00e4\n",
    "r_off = 10.75e4\n",
    "reference_memristor = memtorch.bh.memristor.VTEAM\n",
    "reference_memristor_params = {'time_series_resolution': 1e-10,\n",
    "                              'r_off': r_off,\n",
    "                              'r_on': r_on}\n",
    "model = MobileNetV2().to(device)\n",
    "model.load_state_dict(torch.load('trained_model.pt'), strict=False)\n",
    "patched_model = patch_model(copy.deepcopy(model),\n",
    "                          memristor_model=reference_memristor,\n",
    "                          memristor_model_params=reference_memristor_params,\n",
    "                          module_parameters_to_patch=[torch.nn.Linear, torch.nn.Conv2d],\n",
    "                          mapping_routine=naive_map,\n",
    "                          transistor=True,\n",
    "                          programming_routine=None,\n",
    "                          tile_shape=(128, 128),\n",
    "                          max_input_voltage=0.3,\n",
    "                          ADC_resolution=8,\n",
    "                          ADC_overflow_rate=0.,\n",
    "                          quant_method='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned bh.Conv2d(in_channels=3, out_channels=32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)). Coefficient of determination: 0.999886 [224128.421875, 0.000265]\n",
      "Tuned bh.Conv2d(in_channels=320, out_channels=1280, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0)). Coefficient of determination: 0.999920 [13060.810547, -0.000002]\n",
      "Tuned bh.Linear(in_features=1280, out_features=10, bias=True). Coefficient of determination: 0.999961 [30545.607422, 0.000018]\n",
      "Tuned bh.Conv2d(in_channels=32, out_channels=16, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0)). Coefficient of determination: 0.999951 [107741.460938, -0.000006]\n",
      "Tuned bh.Conv2d(in_channels=16, out_channels=24, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0)). Coefficient of determination: 0.999949 [78823.843750, -0.000016]\n",
      "Tuned bh.Conv2d(in_channels=144, out_channels=24, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0)). Coefficient of determination: 0.999946 [49742.332031, -0.000029]\n",
      "Tuned bh.Conv2d(in_channels=144, out_channels=32, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0)). Coefficient of determination: 0.999935 [80381.250000, 0.000001]\n",
      "Tuned bh.Conv2d(in_channels=192, out_channels=32, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0)). Coefficient of determination: 0.999940 [45748.105469, 0.000006]\n",
      "Tuned bh.Conv2d(in_channels=192, out_channels=32, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0)). Coefficient of determination: 0.999936 [52147.753906, -0.000018]\n",
      "Tuned bh.Conv2d(in_channels=192, out_channels=64, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0)). Coefficient of determination: 0.999925 [54368.273438, 0.000002]\n",
      "Tuned bh.Conv2d(in_channels=384, out_channels=64, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0)). Coefficient of determination: 0.999928 [40946.417969, 0.000009]\n",
      "Tuned bh.Conv2d(in_channels=384, out_channels=64, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0)). Coefficient of determination: 0.999933 [34483.230469, -0.000007]\n",
      "Tuned bh.Conv2d(in_channels=384, out_channels=64, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0)). Coefficient of determination: 0.999920 [39517.199219, -0.000032]\n",
      "Tuned bh.Conv2d(in_channels=64, out_channels=96, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0)). Coefficient of determination: 0.999929 [38159.937500, -0.000002]\n",
      "Tuned bh.Conv2d(in_channels=576, out_channels=96, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0)). Coefficient of determination: 0.999923 [21515.771484, -0.000008]\n",
      "Tuned bh.Conv2d(in_channels=576, out_channels=96, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0)). Coefficient of determination: 0.999919 [23114.511719, -0.000017]\n",
      "Tuned bh.Conv2d(in_channels=576, out_channels=160, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0)). Coefficient of determination: 0.999907 [29668.556641, -0.000001]\n",
      "Tuned bh.Conv2d(in_channels=960, out_channels=160, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0)). Coefficient of determination: 0.999902 [20664.992188, 0.000005]\n",
      "Tuned bh.Conv2d(in_channels=960, out_channels=160, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0)). Coefficient of determination: 0.999904 [15669.416992, -0.000001]\n",
      "Tuned bh.Conv2d(in_channels=160, out_channels=320, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0)). Coefficient of determination: 0.999909 [16107.999023, 0.000002]\n"
     ]
    }
   ],
   "source": [
    "patched_model.tune_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('1')\n",
    "print(test(patched_model, test_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Gws_GLPEGFT"
   },
   "source": [
    "## Device endurance (gradual) simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8z3GixVlEGFT",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import enum\n",
    "# from enum import Enum, auto\n",
    "# from memtorch.mn.Module import supported_module_parameters\n",
    "# import math\n",
    "# import pandas as pd\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# import torch.optim as optim\n",
    "# from torchvision import datasets, transforms\n",
    "# from memtorch.mn.Module import patch_model\n",
    "# from memtorch.map.Module import naive_tune\n",
    "# from memtorch.map.Parameter import naive_map\n",
    "# from memtorch.bh.crossbar.Program import naive_program\n",
    "# from memtorch.bh.nonideality.NonIdeality import apply_nonidealities\n",
    "# from memtorch.bh.crossbar.Crossbar import init_crossbar\n",
    "# import copy\n",
    "# from pprint import pprint\n",
    "# from mobilenetv2 import MobileNetV2\n",
    "# from scipy.interpolate import interp1d\n",
    "# import torchvision\n",
    "\n",
    "\n",
    "# def minimal_tune(model):\n",
    "#     for i, (name, m) in enumerate(list(model.named_modules())):\n",
    "#         if hasattr(m, 'tune'):\n",
    "#             m.transform_output = lambda input: input\n",
    "#             if isinstance(m, memtorch.mn.Conv2d):\n",
    "#                 try:\n",
    "#                     m.transform_output = naive_tune(m, (4, m.in_channels, 8, 8))\n",
    "#                 except:\n",
    "#                     pass\n",
    "#             if isinstance(m, memtorch.mn.Linear):\n",
    "#                 try:\n",
    "#                     m.transform_output = naive_tune(m, (64, m.in_features))\n",
    "#                 except:\n",
    "#                     pass\n",
    "                \n",
    "#     return model.to(device)\n",
    "    \n",
    "# def update_patched_model(patched_model, model):\n",
    "#     for i, (name, m) in enumerate(list(patched_model.named_modules())):\n",
    "#         if isinstance(m, memtorch.mn.Conv2d) or isinstance(m, memtorch.mn.Linear):\n",
    "#             pos_conductance_matrix, neg_conductance_matrix = naive_map(getattr(model, name).weight.data, r_on, r_off,scheme=memtorch.bh.Scheme.DoubleColumn)\n",
    "#             m.crossbars[0].write_conductance_matrix(pos_conductance_matrix, transistor=True, programming_routine=None)\n",
    "#             m.crossbars[1].write_conductance_matrix(neg_conductance_matrix, transistor=True, programming_routine=None)\n",
    "#             m.weight.data = getattr(model, name).weight.data\n",
    "            \n",
    "#     return patched_model\n",
    "    \n",
    "# scale_input = interp1d([1.3, 1.9], [0, 1])\n",
    "# def scale_p_0(p_0, p_1, v_stop, cell_size=10):\n",
    "#     scaled_input = scale_input(v_stop)\n",
    "#     x = 1.50\n",
    "#     y = p_0 * math.exp(p_1 * cell_size)\n",
    "#     k = math.log10(y) / (1 - (2 * scale_input(x) - 1) ** (2))\n",
    "#     new_y = 10 ** (k * (1 - (2 * scaled_input - 1) ** (2)))\n",
    "#     # Backsolve for p_0\n",
    "#     p_0 = new_y / math.exp(p_1 * cell_size)\n",
    "#     return p_0\n",
    "\n",
    "# def gradual(input, cycle_count, p_1, p_2, p_3, cell_size):\n",
    "#     p_0 = torch.log10(input)\n",
    "#     threshold = p_1 * math.exp(p_2 * cell_size)\n",
    "#     return torch.pow(10, (p_3 * cell_size * math.log10(cycle_count) + torch.log10(10 **  p_0) - p_3 * cell_size * math.log10(threshold)))\n",
    "       \n",
    "# def model_gradual(layer, cycle_count, v_stop):\n",
    "#     cell_size = 10\n",
    "#     convergence_point = 1e4\n",
    "#     p_1_lrs = 1.0399076623425807\n",
    "#     p_2_lrs = 0.9171208448973687\n",
    "#     p_3_lrs = 0.0143551595777695\n",
    "#     p_1_hrs = 4.3590883730463410\n",
    "#     p_2_hrs = 0.7738077425228179\n",
    "#     p_3_hrs = -0.018865423084966\n",
    "#     p_1_lrs = scale_p_0(p_1_lrs, p_2_lrs, v_stop)\n",
    "#     p_1_hrs = scale_p_0(p_1_hrs, p_2_hrs, v_stop)\n",
    "#     threshold_lrs = p_1_lrs * math.exp(p_2_lrs * cell_size)\n",
    "#     threshold_hrs = p_1_hrs * math.exp(p_2_hrs * cell_size)\n",
    "#     for i in range(len(layer.crossbars)):\n",
    "#         input = 1 / layer.crossbars[i].conductance_matrix\n",
    "#         if input[input < convergence_point].nelement() > 0:\n",
    "#             if cycle_count > threshold_lrs:\n",
    "#                 input[input < convergence_point] = gradual(input[input < convergence_point], cycle_count, p_1_lrs, p_2_lrs, p_3_lrs, cell_size)\n",
    "#         if input[input > convergence_point].nelement() > 0:\n",
    "#             if cycle_count > threshold_hrs:\n",
    "#                 input[input > convergence_point] = gradual(input[input > convergence_point], cycle_count, p_1_hrs, p_2_hrs, p_3_hrs, cell_size)\n",
    "                \n",
    "#         layer.crossbars[i].conductance_matrix = 1 / input\n",
    "\n",
    "#     return layer\n",
    "\n",
    "# def model_degradation(model, cycle_count, v_stop):\n",
    "#     for i, (name, m) in enumerate(list(model.named_modules())):\n",
    "#         if type(m) in supported_module_parameters.values():\n",
    "#             setattr(model, name, model_gradual(m, cycle_count, v_stop)) # setattr(model.module, name, model_gradual(m, cycle_count, v_stop))\n",
    "\n",
    "                    \n",
    "#     return model\n",
    "\n",
    "# device = torch.device('cuda')\n",
    "# batch_size = 64\n",
    "# transform_train = transforms.Compose([\n",
    "#     transforms.RandomCrop(32, padding=4),\n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "# ])\n",
    "# transform_test = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "# ])\n",
    "# train_set = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "# train_loader = torch.utils.data.DataLoader(train_set, batch_size=256, shuffle=True, num_workers=1)\n",
    "# test_set = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "# test_loader = torch.utils.data.DataLoader(test_set, batch_size=128, shuffle=False, num_workers=1)\n",
    "# reference_memristor = memtorch.bh.memristor.VTEAM\n",
    "# r_on = 4400\n",
    "# r_off = 65000\n",
    "# reference_memristor_params = {'time_series_resolution': 1e-10,\n",
    "#                               'r_off': r_off,\n",
    "#                               'r_on': r_on}\n",
    "# times_to_reprogram = 10 ** np.arange(1, 10, dtype=np.float64)\n",
    "# v_stop_values = np.linspace(1.3, 1.9, 10, endpoint=True)\n",
    "# df = pd.DataFrame(columns=['times_reprogramed', 'v_stop', 'test_set_accuracy'])\n",
    "# for time_to_reprogram in times_to_reprogram:\n",
    "#     cycle_count = time_to_reprogram\n",
    "#     for v_stop in v_stop_values:\n",
    "#         print('time_to_reprogram: %f, v_stop: %f' % (time_to_reprogram, v_stop))\n",
    "#         model = MobileNetV2().to(device)\n",
    "#         model.load_state_dict(torch.load('trained_model.pt'), strict=False)\n",
    "#         model\n",
    "#         patched_model = patch_model(model,\n",
    "#                                   memristor_model=reference_memristor,\n",
    "#                                   memristor_model_params=reference_memristor_params,\n",
    "#                                   module_parameters_to_patch=[torch.nn.Linear, torch.nn.Conv2d],\n",
    "#                                   mapping_routine=naive_map,\n",
    "#                                   transistor=True,\n",
    "#                                   programming_routine=None,\n",
    "#                                   p_l=None,\n",
    "#                                   scheme=memtorch.bh.Scheme.DoubleColumn)\n",
    "#         patched_model = model_degradation(patched_model, cycle_count, v_stop)\n",
    "#         patched_model = minimal_tune(patched_model)\n",
    "#         accuracy = test(patched_model.eval(), test_loader)\n",
    "#         del patched_model\n",
    "#         del model\n",
    "#         df = df.append({'times_reprogramed': time_to_reprogram, 'v_stop': v_stop, 'test_set_accuracy': accuracy}, ignore_index=True)\n",
    "#         df.to_csv('endurance_gradual.csv', index=False)\n",
    "#         if SAVE_GOOGLE_COLAB:\n",
    "#           shutil.copy(\"endurance_gradual.csv\", \"/content/gdrive/My Drive/endurance_gradual.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gAoJaCkkEGFX"
   },
   "source": [
    "## Device endurance (sudden) simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wk7iLeSQEGFX"
   },
   "outputs": [],
   "source": [
    "# import enum\n",
    "# from enum import Enum, auto\n",
    "# from memtorch.mn.Module import supported_module_parameters\n",
    "# import math\n",
    "# import pandas as pd\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# import torch.optim as optim\n",
    "# from torchvision import datasets, transforms\n",
    "# from memtorch.mn.Module import patch_model\n",
    "# from memtorch.map.Module import naive_tune\n",
    "# from memtorch.map.Parameter import naive_map\n",
    "# from memtorch.bh.crossbar.Program import naive_program\n",
    "# from memtorch.bh.nonideality.NonIdeality import apply_nonidealities\n",
    "# from memtorch.bh.crossbar.Crossbar import init_crossbar\n",
    "# import copy\n",
    "# from mobilenetv2 import MobileNetV2\n",
    "# from scipy.interpolate import interp1d\n",
    "# import torchvision\n",
    "\n",
    "\n",
    "# def minimal_tune(model):\n",
    "#     for i, (name, m) in enumerate(list(model.named_modules())):\n",
    "#         if hasattr(m, 'tune'):\n",
    "#             m.transform_output = lambda input: input\n",
    "#             if isinstance(m, memtorch.mn.Conv2d):\n",
    "#                 try:\n",
    "#                     m.transform_output = naive_tune(m, (4, m.in_channels, 8, 8))\n",
    "#                 except:\n",
    "#                     pass\n",
    "#             if isinstance(m, memtorch.mn.Linear):\n",
    "#                 try:\n",
    "#                     m.transform_output = naive_tune(m, (64, m.in_features))\n",
    "#                 except:\n",
    "#                     pass\n",
    "                \n",
    "#     return model.to(device)\n",
    "    \n",
    "# def update_patched_model(patched_model, model):\n",
    "#     for i, (name, m) in enumerate(list(patched_model.named_modules())):\n",
    "#         if isinstance(m, memtorch.mn.Conv2d) or isinstance(m, memtorch.mn.Linear):\n",
    "#             pos_conductance_matrix, neg_conductance_matrix = naive_map(getattr(model, name).weight.data, r_on, r_off,scheme=memtorch.bh.Scheme.DoubleColumn)\n",
    "#             m.crossbars[0].write_conductance_matrix(pos_conductance_matrix, transistor=True, programming_routine=None)\n",
    "#             m.crossbars[1].write_conductance_matrix(neg_conductance_matrix, transistor=True, programming_routine=None)\n",
    "#             m.weight.data = getattr(model, name).weight.data\n",
    "            \n",
    "#     return patched_model\n",
    "\n",
    "# scale_input = interp1d([1.3, 1.9], [0, 1])\n",
    "# def scale_p_0(p_0, p_1, v_stop, cell_size=10):\n",
    "#     scaled_input = scale_input(v_stop)\n",
    "#     x = 1.45\n",
    "#     y = p_0 * cell_size + p_1\n",
    "#     k = math.log10(y) / (1 - (2 * scale_input(x) - 1) ** (2))\n",
    "#     new_y = 10 ** (k * (1 - (2 * scaled_input - 1) ** (2)))\n",
    "#     p_0 = (new_y - p_1) / cell_size\n",
    "#     return p_0\n",
    "       \n",
    "# def model_sudden(layer, cycle_count, v_stop):\n",
    "#     cell_size = 10\n",
    "#     p_1 = 0\n",
    "#     p_0 = 2e7 / cell_size\n",
    "#     p_0 = scale_p_0(p_0, p_1, v_stop)\n",
    "#     threshold = p_0 * cell_size\n",
    "#     if cycle_count > threshold:\n",
    "#         for i in range(len(layer.crossbars)):\n",
    "#             input = layer.crossbars[i].conductance_matrix\n",
    "#             input[input < (1 / 2e4)] = 1 / 2e4\n",
    "#             layer.crossbars[i].conductance_matrix = input\n",
    "            \n",
    "#     return layer\n",
    "\n",
    "# def model_degradation(model, cycle_count, v_stop):\n",
    "#     for i, (name, m) in enumerate(list(model.named_modules())):\n",
    "#         if type(m) in supported_module_parameters.values():\n",
    "#             setattr(model, name, model_sudden(m, cycle_count, v_stop))\n",
    "             \n",
    "#     return model\n",
    "\n",
    "# device = torch.device('cuda')\n",
    "# batch_size = 64\n",
    "# transform_train = transforms.Compose([\n",
    "#     transforms.RandomCrop(32, padding=4),\n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "# ])\n",
    "# transform_test = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "# ])\n",
    "# train_set = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "# train_loader = torch.utils.data.DataLoader(train_set, batch_size=256, shuffle=True, num_workers=1)\n",
    "# test_set = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "# test_loader = torch.utils.data.DataLoader(test_set, batch_size=128, shuffle=False, num_workers=1)\n",
    "# reference_memristor = memtorch.bh.memristor.VTEAM\n",
    "# r_on = 2.00e4\n",
    "# r_off = 10.75e4\n",
    "# reference_memristor_params = {'time_series_resolution': 1e-10,\n",
    "#                               'r_off': r_off,\n",
    "#                               'r_on': r_on}\n",
    "# times_to_reprogram = 10 ** np.arange(1, 10, dtype=np.float64)\n",
    "# v_stop_values = np.linspace(1.3, 1.9, 10, endpoint=True)\n",
    "# df = pd.DataFrame(columns=['times_reprogramed', 'v_stop', 'test_set_accuracy'])\n",
    "# for time_to_reprogram in times_to_reprogram:\n",
    "#     cycle_count = len(train_loader.dataset) * time_to_reprogram\n",
    "#     for v_stop in v_stop_values:\n",
    "#         print('time_to_reprogram: %f, v_stop: %f' % (time_to_reprogram, v_stop))\n",
    "#         model = MobileNetV2().to(device)\n",
    "#         model.load_state_dict(torch.load('trained_model.pt'), strict=False)\n",
    "#         model.eval()\n",
    "#         patched_model = patch_model(model,\n",
    "#                                   memristor_model=reference_memristor,\n",
    "#                                   memristor_model_params=reference_memristor_params,\n",
    "#                                   module_parameters_to_patch=[torch.nn.Linear, torch.nn.Conv2d],\n",
    "#                                   mapping_routine=naive_map,\n",
    "#                                   transistor=True,\n",
    "#                                   programming_routine=None,\n",
    "#                                   p_l=None,\n",
    "#                                   scheme=memtorch.bh.Scheme.DoubleColumn)\n",
    "#         patched_model = model_degradation(patched_model, cycle_count, v_stop)\n",
    "#         patched_model = minimal_tune(patched_model)\n",
    "#         accuracy = test(patched_model, test_loader)\n",
    "#         del patched_model\n",
    "#         del model\n",
    "#         df = df.append({'times_reprogramed': time_to_reprogram, 'v_stop': v_stop, 'test_set_accuracy': accuracy}, ignore_index=True)\n",
    "#         df.to_csv('endurance_sudden.csv', index=False)\n",
    "#         if SAVE_GOOGLE_COLAB:\n",
    "#           shutil.copy(\"endurance_sudden.csv\", \"/content/gdrive/My Drive/endurance_sudden.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kcRNelpJEGFZ"
   },
   "source": [
    "## Device retention (gradual) simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bwHbxLqmEGFa",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import enum\n",
    "# from enum import Enum, auto\n",
    "# import math\n",
    "# import pandas as pd\n",
    "# from memtorch.mn.Module import supported_module_parameters\n",
    "# import math\n",
    "# from memtorch.mn.Module import patch_model\n",
    "# from memtorch.map.Module import naive_tune\n",
    "# from memtorch.map.Parameter import naive_map\n",
    "# from memtorch.bh.crossbar.Program import naive_program\n",
    "# from memtorch.bh.nonideality.NonIdeality import apply_nonidealities\n",
    "# from memtorch.bh.crossbar.Crossbar import init_crossbar\n",
    "# import copy\n",
    "# from mobilenetv2 import MobileNetV2\n",
    "# from scipy.interpolate import interp1d\n",
    "# import torchvision\n",
    "\n",
    "\n",
    "# class OperationMode(Enum):\n",
    "#     sudden = auto()\n",
    "#     gradual = auto()\n",
    "\n",
    "    \n",
    "# def minimal_tune(model):\n",
    "#     for i, (name, m) in enumerate(list(model.named_modules())):\n",
    "#         if hasattr(m, 'tune'):\n",
    "#             m.transform_output = lambda input: input\n",
    "#             if isinstance(m, memtorch.mn.Conv2d):\n",
    "#                 m.transform_output = naive_tune(m, (4, m.in_channels, 8, 8))\n",
    "#             if isinstance(m, memtorch.mn.Linear):\n",
    "#                 m.transform_output = naive_tune(m, (64, m.in_features))\n",
    "                \n",
    "#     return model.to(device)\n",
    "    \n",
    "# def gradual(input, x, p_0, p_1, p_2, p_3, cell_size, tempurature):\n",
    "#     p_0 = p_0 / input\n",
    "#     if tempurature > 298:\n",
    "#         input = torch.pow(10, p_0 * tempurature + torch.log10(input) - p_0 * 298)\n",
    "        \n",
    "#     p_0 = torch.log10(input)\n",
    "#     threshold = p_1 * np.exp(p_2 * cell_size)\n",
    "#     return torch.pow(10, (p_3 * cell_size * math.log10(x) + torch.log10(10 **  p_0) - p_3 * cell_size * math.log10(threshold)))\n",
    "    \n",
    "# def model_gradual(layer, x, tempurature):\n",
    "#     cell_size = 10\n",
    "#     convergence_point = 180000\n",
    "#     p_0_lrs = 0.000801158151673717 * 2400\n",
    "#     p_0_hrs = 0.00420717061486765 * 55000\n",
    "#     p_1 = 0.5\n",
    "#     p_2 = 0.7600902459542083\n",
    "#     p_3_lrs = 0.006489105105825544  \n",
    "#     p_3_hrs = -0.007240917429683966\n",
    "#     threshold_lrs = p_1 * math.exp(p_2 * cell_size)\n",
    "#     threshold_hrs = p_1 * math.exp(p_2 * cell_size)\n",
    "#     for i in range(len(layer.crossbars)):\n",
    "#         input = 1 / layer.crossbars[i].conductance_matrix\n",
    "#         if input[input < convergence_point].nelement() > 0:\n",
    "#             if x > threshold_lrs:\n",
    "#                 input[input < convergence_point] = gradual(input[input < convergence_point], time_, p_0_lrs, p_1, p_2, p_3_lrs, cell_size, tempurature)\n",
    "#         if input[input > convergence_point].nelement() > 0:\n",
    "#             if x > threshold_hrs:\n",
    "#                 input[input > convergence_point] = gradual(input[input > convergence_point], time_, p_0_hrs, p_1, p_2, p_3_hrs, cell_size, tempurature)\n",
    "\n",
    "#         layer.crossbars[i].conductance_matrix = 1 / input\n",
    "\n",
    "#     return layer\n",
    "    \n",
    "# def model_degradation(model, time_, operation_mode, tempurature):\n",
    "#     for i, (name, m) in enumerate(list(model.named_modules())):\n",
    "#         if type(m) in supported_module_parameters.values():\n",
    "#             if len(name.split('.')) > 1:\n",
    "#                 name = name.split('.')[1]\n",
    "\n",
    "#             if operation_mode == OperationMode.gradual:\n",
    "#                 if hasattr(model, 'module'):\n",
    "#                     setattr(model.module, name, model_gradual(m, time_, tempurature))\n",
    "#                 else:\n",
    "#                     setattr(model, name, model_gradual(m, time_, tempurature))\n",
    "#             elif operation_mode == OperationMode.sudden:\n",
    "#                 if hasattr(model, 'module'):\n",
    "#                     setattr(model.module, name, model_sudden(m, time_, tempurature))\n",
    "#                 else:\n",
    "#                     setattr(model, name, model_sudden(m, time_, tempurature))\n",
    "                    \n",
    "#     return model\n",
    "\n",
    "# device = torch.device('cuda')\n",
    "# transform_train = transforms.Compose([\n",
    "#     transforms.RandomCrop(32, padding=4),\n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "# ])\n",
    "# transform_test = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "# ])\n",
    "# train_set = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "# train_loader = torch.utils.data.DataLoader(train_set, batch_size=256, shuffle=True, num_workers=1)\n",
    "# test_set = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "# test_loader = torch.utils.data.DataLoader(test_set, batch_size=128, shuffle=False, num_workers=1)\n",
    "# reference_memristor = memtorch.bh.memristor.VTEAM\n",
    "# r_on = 9e4\n",
    "# r_off = 330000\n",
    "# reference_memristor_params = {'time_series_resolution': 1e-10,\n",
    "#                               'r_off': r_off,\n",
    "#                               'r_on': r_on}\n",
    "# times = 10 ** np.arange(1, 10, dtype=np.float64)\n",
    "# tempuratures = np.linspace(75, 175, 10, endpoint=True)\n",
    "# df = pd.DataFrame(columns=['time', 'tempurature', 'test_set_accuracy'])\n",
    "# for time_ in times:\n",
    "#     print(time_)\n",
    "#     for tempurature in tempuratures:\n",
    "#         tempurature += 273\n",
    "#         model = MobileNetV2().to(device)\n",
    "#         model.load_state_dict(torch.load('trained_model.pt'), strict=False)\n",
    "#         model.eval()\n",
    "#         patched_model = patch_model(model,\n",
    "#                                   memristor_model=reference_memristor,\n",
    "#                                   memristor_model_params=reference_memristor_params,\n",
    "#                                   module_parameters_to_patch=[torch.nn.Linear, torch.nn.Conv2d],\n",
    "#                                   mapping_routine=naive_map,\n",
    "#                                   transistor=True,\n",
    "#                                   programming_routine=None,\n",
    "#                                   p_l=None,\n",
    "#                                   scheme=memtorch.bh.Scheme.DoubleColumn)\n",
    "\n",
    "#         patched_model = minimal_tune(patched_model)\n",
    "#         patched_model = model_degradation(patched_model, time_, OperationMode.gradual, tempurature)\n",
    "#         accuracy = test(patched_model, test_loader)\n",
    "#         del patched_model\n",
    "#         df = df.append({'time': time_, 'tempurature': tempurature, 'test_set_accuracy': accuracy}, ignore_index=True)\n",
    "#         df.to_csv('retention_gradual.csv', index=False)\n",
    "#         if SAVE_GOOGLE_COLAB:\n",
    "#           shutil.copy(\"retention_gradual.csv\", \"/content/gdrive/My Drive/retention_gradual.csv\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "large_scale_simulations.ipynb",
   "provenance": []
  },
  "environment": {
   "name": "pytorch-gpu.1-4.m48",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m48"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
